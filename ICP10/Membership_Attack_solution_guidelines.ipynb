{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack - solution guidelines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amngb95/AI_CyberSecurity/blob/master/ICP10/Membership_Attack_solution_guidelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "0a96b422-b92a-406a-fc92-878e0a57f3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = 'content/drive/My Drive/Membership Attack - solution guidelines/'"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "5523fda2-5557-48dd-800a-21f6b99412b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "5061c4a9-72cd-4bb1-b006-8ede79e85a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "horse plane  deer  bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nizKBfaFbWFhYlAn+P2smHdE52IXvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "211564b4-0b12-4139-a25e-b8b1bb9a1252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "aa970aae-45d5-459c-af68-4554540d4b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "4f2842fa-0bf5-4ea0-a038-d74f5035369b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7955575518291016\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4942553851305675\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3155339718474757\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.178359248106132\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0637284225362647\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9694535444916972\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.912407918221048\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8383980090432155\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7855758569810701\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7344574694720614\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.6965820658046876\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6725745440729897\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6285112106319889\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6036112505342345\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5743053907104542\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5470405659635963\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5169817182947608\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.49678411115141935\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.46918659795390066\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.45854159757075713\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYjPJmDF4le-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36207a2b-250c-4656-d69f-441e1474724c"
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "c9a142df-b30e-438d-8ad6-97d097f1ee72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.7927880066130168\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4514841378649788\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.282268824784652\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.151629485894957\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0378908379303524\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9618580907659458\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8864422092962143\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8305586696700062\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7828396789329436\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7289021830729512\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.6817865009941256\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6493049782064869\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6302434260506764\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.5894779726824797\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5666195429156503\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5293404635070534\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5128067332031705\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.48708091993504166\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.47522422922132035\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4429669830700397\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxx4IAURTgVu",
        "colab_type": "code",
        "outputId": "b471a20f-ceeb-4f9e-d187-ea6f5de8e538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP3trGpP1pgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URhzaw2M1s9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q9Qas1q1zTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "eed8e008-2115-4715-a502-812d6c0092e6"
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([2.0623040e-07, 4.2443118e-11, 9.6106488e-01, 6.2435772e-04,\n",
            "       1.9232506e-05, 3.8259301e-02, 5.9443146e-06, 2.5951742e-05,\n",
            "       1.3476252e-07, 7.1791368e-09], dtype=float32), 1]\n",
            "[array([0.02980977, 0.06981842, 0.42093268, 0.12594901, 0.0596743 ,\n",
            "       0.05742434, 0.14046012, 0.03020487, 0.05302887, 0.0126976 ],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIdV_a8M13Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT3bcbHd181G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf4JO-Q-2BFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMif-8TcEqMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "095b9b9c-76c8-4fcd-8548-862ef6f24f26"
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqn-IKOiEsnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QceavPch2Erb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17dec6cc-ea00-4648-89fd-e01780165410"
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT9ejMDm2JDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "35f5be87-34ca-4657-896b-43a9bab3b9f6"
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06934330311059952\n",
            "Training loss: 0.06933096411943436\n",
            "Training loss: 0.0693298801612854\n",
            "Training loss: 0.06932059327125549\n",
            "Training loss: 0.06932435631036758\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kOdXANW2O1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsrRsmi52Shx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3D8YRAU2V5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "508a91b5-22f1-4d32-b24f-8ebb7ba27d5c"
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}