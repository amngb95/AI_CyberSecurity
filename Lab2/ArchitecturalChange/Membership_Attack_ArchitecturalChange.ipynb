{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Membership Attack -ArchitecturalChange.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amngb95/AI_CyberSecurity/blob/master/Lab2/ArchitecturalChange/Membership_Attack_ArchitecturalChange.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "8ca9e5c3-efe1-45fd-89dd-27a411ee2fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "4ff124a1-bec9-44a2-a301-b36f42dea83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "3d6e1aef-b525-4e8a-90b6-0686223c47b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " deer  bird  frog  deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCP4PS8fi9IgXYAIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "013f0e62-4715-49e3-c935-1aa513013a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O39H-xzClPgh",
        "colab_type": "code",
        "outputId": "a16fd611-bf0b-4433-b669-9856bcf842c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "84d34e49-d9f4-4e65-8b2e-16726972abd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.844213959048776\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.5448975216244798\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3618419612841228\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.2184488006755518\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0899413946034657\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9960703638660938\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.9190857597171803\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8457488434584549\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7920759135804822\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7559250553931727\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7104374828850827\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6731721959874758\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6338719554779018\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6074461996593439\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5694995007151381\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5510338846405926\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5197333795925998\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5107962254796873\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4682631808549852\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4619843112090436\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "dc6d5edb-3345-49f6-92b4-cee246ae861a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "bced4f6d-aa75-46a8-90fc-9703efb6bba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8093747531666475\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.5142317857888654\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3193846364003008\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.172438445298568\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.057109303829615\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9742440627816388\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8982802991519498\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8414589045450206\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.8020077530685288\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7530175154204564\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7124967856709\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.67073169243915\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6423793485021347\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6065052205892018\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5732286515100228\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5566928619066315\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5402838992278861\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5080006299445124\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4856681382126363\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4626040458583923\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "f68eea89-623d-40a0-db32-fa231c8b2ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 75 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaD8_N34l3Eh",
        "colab_type": "code",
        "outputId": "7a83cbc9-130d-4364-d825-43f7c9b64182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[17000])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([1.8292866e-03, 5.8659331e-05, 1.2034194e-01, 6.2054384e-01,\n",
            "       1.0667230e-02, 6.0949408e-02, 1.2564324e-01, 5.5380311e-02,\n",
            "       2.3165119e-03, 2.2696590e-03], dtype=float32), 1]\n",
            "[array([0.05981403, 0.21945778, 0.13155383, 0.10424376, 0.03352866,\n",
            "       0.10070298, 0.06411671, 0.14028227, 0.06292079, 0.08337925],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaKjRRUl6Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl56BLIpl8Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yEnRcZW6sUY",
        "colab_type": "code",
        "outputId": "808bf648-e77f-497a-beb3-06b4960c5cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZ2tfJzl94s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJFbXp8umAam",
        "colab_type": "code",
        "outputId": "07055cb6-50e4-48f0-eaa3-897eeecaa305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU012hhrmDvi",
        "colab_type": "code",
        "outputId": "4c280087-1a0e-4ba9-d26c-20c2dd4cac5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06934548192739487\n",
            "Training loss: 0.0693316250705719\n",
            "Training loss: 0.06933225837469101\n",
            "Training loss: 0.06933006760120392\n",
            "Training loss: 0.06931780847787856\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWR_CXQEmIC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecc2gaFmHnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNVIg-FHsFv",
        "colab_type": "code",
        "outputId": "9f7254db-e079-47e6-dae6-dc0aa6db14bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}